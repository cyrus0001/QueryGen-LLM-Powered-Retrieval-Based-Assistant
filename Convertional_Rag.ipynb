{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wg65tORxb6l",
        "outputId": "14a3477c-b1cf-48bc-e4e7-43bbef475315"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.5/305.5 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchainhub langchain-community langchain-core langchain-groq pypdf docx2txt python-docx pandas beautifulsoup4 markdown sentence-transformers faiss-cpu tiktoken\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eK6Vbr9jxdH3",
        "outputId": "f056a815-c5e3-4202-c26d-9d54b20d2b21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.3.26\n"
          ]
        }
      ],
      "source": [
        "import langchain\n",
        "print(langchain.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vn9IC8mlxwiZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = \"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qimgFCFHA0ib",
        "outputId": "37bb3e5b-6822-4651-e723-c18dd640f3af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content=\"Here's one:\\n\\nWhy couldn't the bicycle stand up by itself?\\n\\n(wait for it...)\\n\\nBecause it was two-tired!\\n\\nHope that made you laugh!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 14, 'total_tokens': 46, 'completion_time': 0.031843546, 'prompt_time': 0.00398632, 'queue_time': 0.164348829, 'total_time': 0.035829866}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e', 'finish_reason': 'stop', 'logprobs': None}, id='run--574390bf-7ea4-46c4-8582-6d3532a56fcb-0', usage_metadata={'input_tokens': 14, 'output_tokens': 32, 'total_tokens': 46})"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"llama3-8b-8192\",  # or \"llama3-70b-8192\"\n",
        "    temperature=0.7,\n",
        ")\n",
        "\n",
        "llm_response = llm.invoke(\"Tell me a joke\")\n",
        "\n",
        "llm_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "TivSuFOZ-a6j",
        "outputId": "f9943405-d07d-480b-b390-9144e58c228f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Here's one:\\n\\nWhy couldn't the bicycle stand up by itself?\\n\\n(wait for it...)\\n\\nBecause it was two-tired!\\n\\nHope that made you laugh!\""
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "output_parser = StrOutputParser()\n",
        "output_parser.invoke(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ZDSqYvuK_ZoY",
        "outputId": "5693a5af-36ad-4231-e86c-cf4042efcb95"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Here's one:\\n\\nWhy couldn't the bicycle stand up by itself?\\n\\n(wait for it...)\\n\\nBecause it was two-tired!\\n\\nHope that made you laugh!\""
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain = llm | output_parser\n",
        "chain.invoke(\"Tell me a joke\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Etz3XOSd0Hl3",
        "outputId": "abd82408-b6ea-44da-e36e-3e4f2e389053"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MobileReview(phone_model='Galaxy S21', rating=4.0, pros=['gorgeous screen', 'insane camera'], cons=['expensive', 'no charger included', 'annoying button layout'], summary='Solid phone with a few quirks')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import List\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class MobileReview(BaseModel):\n",
        "    phone_model: str = Field(description=\"Name and model of the phone\")\n",
        "    rating: float = Field(description=\"Overall rating out of 5\")\n",
        "    pros: List[str] = Field(description=\"List of positive aspects\")\n",
        "    cons: List[str] = Field(description=\"List of negative aspects\")\n",
        "    summary: str = Field(description=\"Brief summary of the review\")\n",
        "\n",
        "review_text = \"\"\"\n",
        "Just got my hands on the new Galaxy S21 and wow, this thing is slick! The screen is gorgeous,\n",
        "colors pop like crazy. Camera's insane too, especially at night - my Insta game's never been\n",
        "stronger. Battery life's solid, lasts me all day no problem.\n",
        "\n",
        "Not gonna lie though, it's pretty pricey. And what's with ditching the charger? C'mon Samsung.\n",
        "Also, still getting used to the new button layout, keep hitting Bixby by mistake.\n",
        "\n",
        "Overall, I'd say it's a solid 4 out of 5. Great phone, but a few annoying quirks keep it from\n",
        "being perfect. If you're due for an upgrade, definitely worth checking out!\n",
        "\"\"\"\n",
        "\n",
        "structured_llm = llm.with_structured_output(MobileReview)\n",
        "output = structured_llm.invoke(review_text)\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pI69FDnf-8Tj",
        "outputId": "5bae52e9-6be3-4b21-addf-4054f1fed17d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['gorgeous screen', 'insane camera']"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output.pros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkJ_zXSoCE2X",
        "outputId": "2efa9bc1-650e-488e-f8bc-4d879a5d9dca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['expensive', 'no charger included', 'annoying button layout']"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output.cons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4LdOeiDCHN7",
        "outputId": "a7bdcb26-9bd9-4e58-a226-0ef4601a415b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[HumanMessage(content='Tell me a short joke about programmer', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "prompt = ChatPromptTemplate.from_template(\"Tell me a short joke about {topic}\")\n",
        "prompt.invoke({\"topic\": \"programmer\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xgkj7mlkCkbb",
        "outputId": "8a2ac12c-c900-4def-809c-6ce62e84fe95"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Why do programmers prefer dark mode?\\n\\nBecause light attracts bugs.'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain = prompt | llm | output_parser\n",
        "chain.invoke({\"topic\":\"programmer\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBHhyBIJCyuE",
        "outputId": "66d27e10-453f-48a4-c72b-08448963ed70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "When paddy is attacked by a severe pest or insect infestation, the farmer may need to use a combination of pest control methods, including pesticides. Here are some common types of pesticides that can be used to control pests that are commonly found in paddy fields:\n",
            "\n",
            "1. **Insecticides**:\n",
            "\t* Organophosphates (e.g., Chlorpyrifos, Malathion): effective against a wide range of pests, including rice stem borers, leaf folders, and planthoppers.\n",
            "\t* Pyrethroids (e.g., Cyhalothrin, Deltamethrin): effective against pests like rice whorl maggots, leafhoppers, and grasshoppers.\n",
            "\t* Neonicotinoids (e.g., Imidacloprid, Thiamethoxam): effective against pests like rice leaf folders, planthoppers, and stem borers.\n",
            "2. **Herbicides**:\n",
            "\t* Selective herbicides (e.g., Glyphosate, 2,4-D): used to control weeds that compete with the paddy crop for water, nutrients, and light.\n",
            "3. **Fungicides**:\n",
            "\t* Carboxin: effective against fungal diseases like rice blast and brown spot.\n",
            "\t* Prochloraz: effective against fungal diseases like rice sheath blight and leaf blight.\n",
            "4. **Bactericides**:\n",
            "\t* Copper-based products: effective against bacterial diseases like rice bacterial leaf blight.\n",
            "5. **Integrated Pest Management (IPM)**:\n",
            "\t* Cultural practices: adjusting planting dates, crop rotation, and irrigation schedules to minimize pest buildup.\n",
            "\t* Biological control: using natural predators, parasites, or pathogens to control pest populations.\n",
            "\t* Resistant varieties: planting rice varieties that have built-in resistance to certain pests or diseases.\n",
            "\n",
            "Some examples of severe pest infestations that may require the use of pesticides in paddy fields include:\n",
            "\n",
            "1. **Rice stem borers** (Chilo suppressalis): a common pest that can cause significant damage to rice plants.\n",
            "2. **Rice leaf folders** (Cnaphalocrocis medinalis): a pest that can cause significant damage to rice leaves.\n",
            "3. **Rice whorl maggots** (Chlorophorus spp.): a pest that can cause significant damage to rice plants.\n",
            "4. **Planthoppers** (Nilaparvata lugens): a pest that can transmit viral diseases to rice plants.\n",
            "\n",
            "It's essential to note that pesticides should be used judiciously and in combination with other IPM practices to minimize the risk of pesticide resistance, environmental contamination, and human health impacts. Additionally, farmers should always follow local regulations and guidelines for pesticide use, and take necessary precautions to ensure safe handling and application of pesticides.\n"
          ]
        }
      ],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Define the prompt\n",
        "prompt = ChatPromptTemplate.from_template(\" Help the farmer {topic}\")\n",
        "\n",
        "# Initialize the LLM model\n",
        "llm = ChatGroq(\n",
        "    model=\"llama3-8b-8192\",  # or \"llama3-70b-8192\"\n",
        "    temperature=0.7,\n",
        ")\n",
        "\n",
        "# Define the output parser\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# Define the chain\n",
        "chain = prompt | llm | output_parser\n",
        "\n",
        "result = chain.invoke({\"topic\":\"What is the different type of pestiside are needed when paddy is attacking some kind of insect which is very dangerous?\"})\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuOXjIEPD9G1",
        "outputId": "7ce0ced9-1612-4d0b-ad8f-f20b937f6cd2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content=\"Programming! It's like trying to solve a puzzle, except the puzzle is trying to solve you back!\\n\\nBut seriously, programming is like building with Legos, except instead of blocks, you're using code to create something amazing. And just like Legos, it can be frustrating when things don't fit together quite right, but the end result is always worth it!\\n\\nHere's a joke to help you debug your code:\\n\\nWhy do programmers prefer dark mode?\\n\\nBecause light attracts bugs!\\n\\nAnd here's another one:\\n\\nWhy do programmers prefer coffee?\\n\\nBecause it's a bug-free drink!\\n\\nOkay, okay, I'll stop with the puns now. But programming is really all about creativity and problem-solving. With the right tools and mindset, you can create something truly amazing!\\n\\nSo, what do you want to build next?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 166, 'prompt_tokens': 28, 'total_tokens': 194, 'completion_time': 0.184370497, 'prompt_time': 0.005201038, 'queue_time': 0.169290257, 'total_time': 0.189571535}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8b7c3a83f7', 'finish_reason': 'stop', 'logprobs': None}, id='run--87695186-eb55-48a9-a7ea-1dd963c9463f-0', usage_metadata={'input_tokens': 28, 'output_tokens': 166, 'total_tokens': 194})"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "system_message = SystemMessage(content=\"You are a helpful assistant that tells jokes.\")\n",
        "human_message = HumanMessage(content=\"Tell me about programming\")\n",
        "llm.invoke([system_message, human_message])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfZ3wwvREDEG",
        "outputId": "96e71367-0f1e-4024-ad17-49ba6bdca5f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant that tells jokes.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me about programming', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "template = ChatPromptTemplate([\n",
        "    (\"system\", \"You are a helpful assistant that tells jokes.\"),\n",
        "    (\"human\", \"Tell me about {topic}\")\n",
        "])\n",
        "\n",
        "prompt_value = template.invoke(\n",
        "    {\n",
        "        \"topic\": \"programming\"\n",
        "    }\n",
        ")\n",
        "prompt_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRQfP9QuEHbI",
        "outputId": "96221995-e2ad-4f37-8e5b-c916a0dcfc76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Programming! It\\'s like trying to teach a computer to do a backflip... but instead of a backflip, it\\'s just a bunch of code that makes a website work. \\n\\nBut seriously, programming is like being a master builder, constructing entire worlds (or at least, really cool websites and apps) with just a few lines of code. And just like how you need the right tools and materials to build a house, programmers need the right programming languages and tools to create their digital masterpieces.\\n\\nHere\\'s a joke to help you \"debug\" your understanding of programming:\\n\\nWhy do programmers prefer dark mode?\\n\\nBecause light attracts bugs!\\n\\nHope that made you LOL! Do you have any specific questions about programming or would you like to hear another joke?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 152, 'prompt_tokens': 28, 'total_tokens': 180, 'completion_time': 0.168612086, 'prompt_time': 0.004889884, 'queue_time': 0.16941715, 'total_time': 0.17350197}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8b7c3a83f7', 'finish_reason': 'stop', 'logprobs': None}, id='run--71fce30d-6d9c-441b-9750-6df2384a278d-0', usage_metadata={'input_tokens': 28, 'output_tokens': 152, 'total_tokens': 180})"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke(prompt_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ef0dFu5EEYaO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
